{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea832f87-92b1-4b9f-81c4-baacde5fa3eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:29:03.188102Z",
     "iopub.status.busy": "2024-08-05T09:29:03.187737Z",
     "iopub.status.idle": "2024-08-05T09:29:06.373747Z",
     "shell.execute_reply": "2024-08-05T09:29:06.372921Z",
     "shell.execute_reply.started": "2024-08-05T09:29:03.188069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (2.6.3)\n",
      "Requirement already satisfied: tiktoken in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: einops in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: triton in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: pytest in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (8.3.2)\n",
      "Requirement already satisfied: torch in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from flash-attn) (2.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: filelock in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from triton) (3.13.1)\n",
      "Requirement already satisfied: iniconfig in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pytest) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pytest) (23.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pytest) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pytest) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from pytest) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Requirement already satisfied: typing-extensions in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from jinja2->torch->flash-attn) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from sympy->torch->flash-attn) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install flash-attn tiktoken einops triton python-dotenv pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68e562c-4b89-479a-9b60-72991e113e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:29:10.928431Z",
     "iopub.status.busy": "2024-08-05T09:29:10.928034Z",
     "iopub.status.idle": "2024-08-05T09:29:12.618039Z",
     "shell.execute_reply": "2024-08-05T09:29:12.617433Z",
     "shell.execute_reply.started": "2024-08-05T09:29:10.928403Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from minsearch import Index\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/run/cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa388d7-6da8-4751-8106-c335b971e183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:29:16.053747Z",
     "iopub.status.busy": "2024-08-05T09:29:16.052933Z",
     "iopub.status.idle": "2024-08-05T09:32:17.316051Z",
     "shell.execute_reply": "2024-08-05T09:32:17.315352Z",
     "shell.execute_reply.started": "2024-08-05T09:29:16.053710Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3025c66d4bb4f7cbaf0413cd999f3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "model_id = \"microsoft/Phi-3-small-128k-instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=\"auto\",\n",
    "  \n",
    "    \n",
    "    trust_remote_code=True\n",
    ")\n",
    "assert torch.cuda.is_available(), \"This model needs a GPU to run ...\"\n",
    "device = torch.cuda.current_device()\n",
    "model = model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,  trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c177f03-5f3c-4f15-920c-2cb39ffe180c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:32:53.868679Z",
     "iopub.status.busy": "2024-08-05T09:32:53.868164Z",
     "iopub.status.idle": "2024-08-05T09:32:53.873106Z",
     "shell.execute_reply": "2024-08-05T09:32:53.872288Z",
     "shell.execute_reply.started": "2024-08-05T09:32:53.868646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available(), torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/run/cache/modules/transformers_modules/microsoft/Phi-3-small-128k-instruct/f80aaa30bfc64c2b8ab214b541d9050e97163bc4/triton_flash_blocksparse_attn.py:88: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  x = [xi.to_sparse_csr() for xi in x]\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")\n",
    "# not generation_args:\n",
    "generation_args = {\n",
    "        \"max_new_tokens\": 500,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 0.0,\n",
    "        \"do_sample\": False\n",
    "    }\n",
    "\n",
    "output = pipe(\"How to get rid of errors in kernel for jupyter notebook\", **generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e8f677-a5a5-4786-acbd-a26f2d159a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:32:55.143081Z",
     "iopub.status.busy": "2024-08-05T09:32:55.142696Z",
     "iopub.status.idle": "2024-08-05T09:32:55.151001Z",
     "shell.execute_reply": "2024-08-05T09:32:55.150379Z",
     "shell.execute_reply.started": "2024-08-05T09:32:55.143054Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "with open('documents.json', 'r') as file:\n",
    "\n",
    "    docs = json.load(file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e62486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74440260-3757-44b1-acb8-41c66f3533b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:32:56.078246Z",
     "iopub.status.busy": "2024-08-05T09:32:56.077871Z",
     "iopub.status.idle": "2024-08-05T09:32:56.082270Z",
     "shell.execute_reply": "2024-08-05T09:32:56.081544Z",
     "shell.execute_reply.started": "2024-08-05T09:32:56.078220Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "\n",
    "    for document in doc['documents']:\n",
    "\n",
    "        document['course'] = doc['course'] \n",
    "        documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97d96165-f38e-42f1-99ab-2da82d78c452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:32:56.948324Z",
     "iopub.status.busy": "2024-08-05T09:32:56.947947Z",
     "iopub.status.idle": "2024-08-05T09:32:57.193762Z",
     "shell.execute_reply": "2024-08-05T09:32:57.193099Z",
     "shell.execute_reply.started": "2024-08-05T09:32:56.948300Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7feadb3a4fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfields = [\"text\", \"section\", \"question\"]\n",
    "\n",
    "\n",
    "indobject = Index(text_fields = textfields, keyword_fields = ['course'])\n",
    "indobject.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65550553-6d4a-49b9-857a-b2bc29a012d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:32:59.413530Z",
     "iopub.status.busy": "2024-08-05T09:32:59.413138Z",
     "iopub.status.idle": "2024-08-05T09:32:59.417748Z",
     "shell.execute_reply": "2024-08-05T09:32:59.417012Z",
     "shell.execute_reply.started": "2024-08-05T09:32:59.413505Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query, boost_dict = {\"question\": 3}, filter_dict =  {\"course\":\"mlops-zoomcamp\"}, num_results = 5 ):\n",
    "\n",
    "    context = indobject.search(query = query, boost_dict = boost_dict, filter_dict = filter_dict, num_results = num_results\n",
    "                    )\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccce04cf-887e-4f49-8059-5c3c4aad55db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:33:00.713417Z",
     "iopub.status.busy": "2024-08-05T09:33:00.713032Z",
     "iopub.status.idle": "2024-08-05T09:33:00.718024Z",
     "shell.execute_reply": "2024-08-05T09:33:00.717150Z",
     "shell.execute_reply.started": "2024-08-05T09:33:00.713391Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, related_docs):\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "    You are an assistant for teaching online courses answer the question based on the context provided.\n",
    "    Only the information available in the provided context should be used strictly adhere to this\n",
    "    \n",
    "    question:{query}\n",
    "    \n",
    "    context:{context}\n",
    "    \n",
    "    \n",
    "    \"\"\".strip()\n",
    "    \n",
    "    \n",
    "    context = \"\"\n",
    "    for doc in related_docs:\n",
    "        \n",
    "        context += f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']} \\n\\n\"\n",
    "        \n",
    "    \n",
    "    prompt = prompt.format(query = query, context = context).strip()\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d2f3c7-8301-4c43-8296-ea6064527302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:33:02.193433Z",
     "iopub.status.busy": "2024-08-05T09:33:02.193060Z",
     "iopub.status.idle": "2024-08-05T09:33:02.198386Z",
     "shell.execute_reply": "2024-08-05T09:33:02.197587Z",
     "shell.execute_reply.started": "2024-08-05T09:33:02.193406Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chat(prompt, generation_args = {}):\n",
    "    \n",
    "    messages = [{\"role\":\"user\", \"content\": prompt.strip()}]\n",
    "    pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")\n",
    "    if not generation_args:\n",
    "        generation_args = {\n",
    "        \"max_new_tokens\": 500,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 0.0,\n",
    "        \"do_sample\": False\n",
    "    }\n",
    "\n",
    "    output = pipe(messages, **generation_args)\n",
    "    print(output)\n",
    "    \n",
    "    return output[0]['generated_text']\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b24a2e2b-6352-4ff2-bd74-eac1fb422060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:33:04.443596Z",
     "iopub.status.busy": "2024-08-05T09:33:04.442935Z",
     "iopub.status.idle": "2024-08-05T09:33:04.448032Z",
     "shell.execute_reply": "2024-08-05T09:33:04.447073Z",
     "shell.execute_reply.started": "2024-08-05T09:33:04.443563Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query, boost_dict = {\"question\": 3}, course_filter =  {\"course\": \"data-engineering-zoomcamp\"}, generation_args ={}):\n",
    "    \n",
    "    context = search(query = query, boost_dict = boost_dict, filter_dict = course_filter)\n",
    "    \n",
    "    prompt = build_prompt(query, context)\n",
    "    \n",
    "    answer = chat(prompt, generation_args = generation_args)\n",
    "    \n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a24b43a-3381-49f9-9790-832e4b5b05c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:33:06.008422Z",
     "iopub.status.busy": "2024-08-05T09:33:06.008042Z",
     "iopub.status.idle": "2024-08-05T09:33:06.011574Z",
     "shell.execute_reply": "2024-08-05T09:33:06.010937Z",
     "shell.execute_reply.started": "2024-08-05T09:33:06.008396Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How to run spark engine ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95975222-73b6-4cda-90c1-843cfe80f735",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:33:17.353235Z",
     "iopub.status.busy": "2024-08-05T09:33:17.352853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/run/cache/modules/transformers_modules/microsoft/Phi-3-small-128k-instruct/f80aaa30bfc64c2b8ab214b541d9050e97163bc4/triton_flash_blocksparse_attn.py:88: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  x = [xi.to_sparse_csr() for xi in x]\n"
     ]
    }
   ],
   "source": [
    "answer = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab650c-6709-4082-b6c4-6264e221aa35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
